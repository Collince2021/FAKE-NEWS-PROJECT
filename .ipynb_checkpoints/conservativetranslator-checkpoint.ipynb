{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4323fe2-57e6-408e-87f7-719dd7d84771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Loading Helsinki English-to-Swahili translation model\n",
    "helsinki_model_name = \"Helsinki-NLP/opus-mt-en-sw\"\n",
    "helsinki_tokenizer = MarianTokenizer.from_pretrained(helsinki_model_name)\n",
    "helsinki_model = MarianMTModel.from_pretrained(helsinki_model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading Bildad English-to-Swahili translation model\n",
    "bildad_model_name = \"Bildad-Model/en-sw\" \n",
    "bildad_tokenizer = MarianTokenizer.from_pretrained(bildad_model_name)\n",
    "bildad_model = MarianMTModel.from_pretrained(bildad_model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading dataset\n",
    "input_file = \"/content/sample_data/Fake Clean.csv\"\n",
    "output_file = \"/content/sample_data/fake_Translated_Swahili.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "def load_existing_translations(file_path, df_part):\n",
    "    \"\"\"We Load existing translations if it is available, otherwise we initialize the column.\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        translated_df = pd.read_csv(file_path)\n",
    "        if \"translated_text\" in translated_df.columns:\n",
    "            df_part[\"translated_text\"] = translated_df[\"translated_text\"]\n",
    "        else:\n",
    "            df_part[\"translated_text\"] = \"\"  # Ensuring column exists\n",
    "    else:\n",
    "        df_part[\"translated_text\"] = \"\"  # Ensuring column exists\n",
    "    return df_part\n",
    "\n",
    "# Loading existing translations if available\n",
    "df = load_existing_translations(output_file, df)\n",
    "\n",
    "def get_confident_translation(text, model1, tokenizer1, model2, tokenizer2, confidence_threshold=0.5):\n",
    "    \"\"\"Translate using two models and return the translation with the highest minimum token confidence.\"\"\"\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return text  # Skipping empty values\n",
    "    \n",
    "    try:\n",
    "        # Translateing using Model 1 (Helsinki)\n",
    "        inputs1 = tokenizer1(text, return_tensors=\"pt\", padding=True, truncation=True).to(model1.device)\n",
    "        outputs1 = model1.generate(**inputs1, return_dict_in_generate=True, output_scores=True)\n",
    "        translation1 = tokenizer1.decode(outputs1.sequences[0], skip_special_tokens=True)\n",
    "        score1 = min([t.item() for t in outputs1.scores[0]])  # Minimum token confidence\n",
    "\n",
    "        # Translating using Model 2 (Bildad)\n",
    "        inputs2 = tokenizer2(text, return_tensors=\"pt\", padding=True, truncation=True).to(model2.device)\n",
    "        outputs2 = model2.generate(**inputs2, return_dict_in_generate=True, output_scores=True)\n",
    "        translation2 = tokenizer2.decode(outputs2.sequences[0], skip_special_tokens=True)\n",
    "        score2 = min([t.item() for t in outputs2.scores[0]])\n",
    "\n",
    "        # Select the translation with the highest minimum confidence\n",
    "        if score1 >= confidence_threshold and score2 >= confidence_threshold:\n",
    "            return translation1 if score1 > score2 else translation2\n",
    "        elif score1 >= confidence_threshold:\n",
    "            return translation1\n",
    "        elif score2 >= confidence_threshold:\n",
    "            return translation2\n",
    "        else:\n",
    "            return \"Low confidence translation. Needs review.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating: {e}\")\n",
    "        return text  # Returns original text if translation fails\n",
    "\n",
    "def translate_and_save(df_part, file_path):\n",
    "    \"\"\"Translating the text and saving it only if it is not already translated.\"\"\"\n",
    "    tqdm.pandas()\n",
    "    for index, row in df_part.iterrows():\n",
    "        if pd.isna(row.get(\"translated_text\", \"\")) or row[\"translated_text\"].strip() == \"\":\n",
    "            translated_text = get_confident_translation(row[\"text\"], helsinki_model, helsinki_tokenizer, bildad_model, bildad_tokenizer)\n",
    "            df_part.at[index, \"translated_text\"] = translated_text\n",
    "            df_part.to_csv(file_path, index=False)  # Saves after each translation\n",
    "\n",
    "# calling Translate and save method\n",
    "translate_and_save(df, output_file)\n",
    "\n",
    "print(\"Dataset successfully translated and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40c819-4fc9-4481-b406-32ed0e677cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
